{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common_23 as common #This file works in Python 3. video works in python2\n",
    "import video_23 as video #This file works in Python 3. video works for python2\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time \n",
    "import sys\n",
    "from contextlib import contextmanager\n",
    "import itertools as it\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert file folder to video if you have frame sequences instead of a video\n",
    "def fr2vid(inputpath, outputfile):\n",
    "    pathIn= inputpath\n",
    "    pathOut = outputfile\n",
    "    fps = 32\n",
    "    frame_array = []\n",
    "    files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    "    #for sorting the file names properly\n",
    "    files.sort(key = lambda x: x[5:-4])\n",
    "    files.sort()\n",
    "    frame_array = []\n",
    "    files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    "    #for sorting the file names properly\n",
    "    files.sort(key = lambda x: x[5:-4])\n",
    "    for i in range(len(files)):\n",
    "        filename=pathIn + files[i]\n",
    "        #reading each files\n",
    "        img = cv2.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "    \n",
    "        #inserting the frames into an image array\n",
    "        frame_array.append(img)\n",
    "    out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "    for i in range(len(frame_array)):\n",
    "        # writing to a image array\n",
    "        out.write(frame_array[i])\n",
    "    out.release()\n",
    "\n",
    "#fr2vid('./house/','house.avi') #convert sequence to video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homework 3 -- Motion Segmentation helper code\n",
    "\n",
    "def motion_seg(inputfile):\n",
    "    cap = video.create_capture(inputfile)\n",
    "    ret, first = cap.read()\n",
    "\n",
    "    # For background subtraction, Save the first image as reference\n",
    "    first_gray = cv2.cvtColor(first, cv2.COLOR_BGR2GRAY)\n",
    "    first_gray = cv2.GaussianBlur(first_gray, (21, 21), 0)\n",
    "    start = time.time()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "    \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "        # In each iteration, calculate absolute difference between current frame and reference frame\n",
    "        difference = cv2.absdiff(gray, first_gray)\n",
    "\n",
    "        # Apply thresholding to eliminate noise\n",
    "        thresh = cv2.threshold(difference, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "        thresh = cv2.dilate(thresh, None, iterations=5)\n",
    "        \n",
    "        cv2.imshow(\"thresh\", thresh)\n",
    "        key = cv2.waitKey(1) & 0xFF \n",
    "        # if the `q` key is pressed, break from the lop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9704020023345947\n"
     ]
    }
   ],
   "source": [
    "motion_seg('railway.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non Adaptive frame differencing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this type of frame differencing, the background model is replaced with that of the previous image at each iteration. It is very quick to adapt to changes in lighting. Objects that stop are no longer detected. Objects that start up do not leave behind the ghosts. Very difficult to detect an object moving towards or away from the camera.  \n",
    "\n",
    "Thresholds = [0,5,10,15,20,25,30]\n",
    "\n",
    "As the threshold value increases, the motion of the objects and the object itself gets insignificant. Even low threshold values do not show significant motion. Threshold value of 10 seems optimal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non - Adaptive Backgrounding\n",
    "def nonAdaptiveFD(inputfile,threshold):\n",
    "    cap = video.create_capture(inputfile)\n",
    "    ret, first = cap.read()\n",
    "\n",
    "    first_gray = cv2.cvtColor(first, cv2.COLOR_BGR2GRAY)\n",
    "    first_gray = cv2.GaussianBlur(first_gray, (21, 21), 0)\n",
    "    start = time.time()\n",
    "    backgroundFrame = first_gray\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "    \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "        currentFrame = gray\n",
    "        \n",
    "        foreground = cv2.absdiff(backgroundFrame, currentFrame)\n",
    "\n",
    "        foreground = cv2.threshold(foreground, threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "        foreground = cv2.dilate(foreground, None, iterations=5)\n",
    "        \n",
    "        cv2.imshow(\"Non Adaptive FD threshold {0}\".format(threshold), foreground)\n",
    "        \n",
    "        backgroundFrame = currentFrame\n",
    "        key = cv2.waitKey(100) & 0xFF \n",
    "    \n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Times to complete for threshold {0} is {1}'.format(threshold, time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times to complete for threshold 10 is 2.6158246994018555\n"
     ]
    }
   ],
   "source": [
    "#Ideal case\n",
    "nonAdaptiveFD('beach.avi', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times to complete for threshold 0 is 2.3468198776245117\n",
      "Times to complete for threshold 5 is 0.6679394245147705\n",
      "Times to complete for threshold 10 is 0.2732706069946289\n",
      "Times to complete for threshold 15 is 0.2902240753173828\n",
      "Times to complete for threshold 20 is 0.32058119773864746\n",
      "Times to complete for threshold 25 is 0.4603567123413086\n",
      "Times to complete for threshold 30 is 0.4360504150390625\n",
      "Times to complete for threshold 0 is 0.6962041854858398\n",
      "Times to complete for threshold 5 is 0.47173523902893066\n",
      "Times to complete for threshold 10 is 0.4597747325897217\n",
      "Times to complete for threshold 15 is 0.40974855422973633\n",
      "Times to complete for threshold 20 is 0.4253976345062256\n",
      "Times to complete for threshold 25 is 0.44284582138061523\n",
      "Times to complete for threshold 30 is 0.6936357021331787\n",
      "Times to complete for threshold 0 is 0.4062070846557617\n",
      "Times to complete for threshold 5 is 0.1874995231628418\n",
      "Times to complete for threshold 10 is 0.1984710693359375\n",
      "Times to complete for threshold 15 is 0.3151555061340332\n",
      "Times to complete for threshold 20 is 0.22439932823181152\n",
      "Times to complete for threshold 25 is 0.2762634754180908\n",
      "Times to complete for threshold 30 is 0.29816746711730957\n",
      "Times to complete for threshold 0 is 0.20046377182006836\n",
      "Times to complete for threshold 5 is 0.4079105854034424\n",
      "Times to complete for threshold 10 is 0.18949484825134277\n",
      "Times to complete for threshold 15 is 0.17454004287719727\n",
      "Times to complete for threshold 20 is 0.21742033958435059\n",
      "Times to complete for threshold 25 is 0.2378101348876953\n",
      "Times to complete for threshold 30 is 0.25830841064453125\n",
      "Times to complete for threshold 0 is 0.14063262939453125\n",
      "Times to complete for threshold 5 is 0.23138046264648438\n",
      "Times to complete for threshold 10 is 0.2712738513946533\n",
      "Times to complete for threshold 15 is 0.21177339553833008\n",
      "Times to complete for threshold 20 is 0.2079756259918213\n",
      "Times to complete for threshold 25 is 0.17830705642700195\n",
      "Times to complete for threshold 30 is 0.19323039054870605\n",
      "Times to complete for threshold 0 is 0.15804314613342285\n",
      "Times to complete for threshold 5 is 0.3563723564147949\n",
      "Times to complete for threshold 10 is 0.345595121383667\n",
      "Times to complete for threshold 15 is 0.3513944149017334\n",
      "Times to complete for threshold 20 is 0.6861658096313477\n",
      "Times to complete for threshold 25 is 0.2518191337585449\n",
      "Times to complete for threshold 30 is 0.3331942558288574\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0,5,10,15,20,25,30]\n",
    "sequences = ['beach.avi', 'trees.avi', 'lights.avi', 'jug.avi', 'railway.avi', 'rock.avi']\n",
    "for sequence in sequences:\n",
    "    for threshold in thresholds:\n",
    "        nonAdaptiveFD(sequence,threshold)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adaptive frame differencing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this type of frame differencing, the current image is blended into the background model with parameter α (blending parameter). \n",
    "\n",
    "If α = 1, it becomes the Non Adaptive frame differencing whereas if α = 0, it gives the simple background subtraction. \n",
    "\n",
    "It is more responsive to changes in illumination and camera motion. Objects that stop and ghosts left behind by the objects that start, gradually fade into the background. \n",
    "\n",
    "As alpha decreases, the time taken for ghosts to disappear increases.\n",
    "\n",
    "alphas = [1, 0.75, 0.5, 0.25, 0]\n",
    "\n",
    "thresholds = [0,5,10,15,20,25,30]\n",
    "\n",
    "Alpha of 0.5 and Threshold of 10 usually give good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive Backgrounding\n",
    "def adaptiveFD(inputfile,alpha,threshold):\n",
    "    cap = video.create_capture(inputfile)\n",
    "    ret, first = cap.read()\n",
    "    \n",
    "    first_gray = cv2.cvtColor(first, cv2.COLOR_BGR2GRAY)\n",
    "    first_gray = cv2.GaussianBlur(first_gray, (21, 21), 0)\n",
    "    start = time.time()\n",
    "    backgroundFrame = first_gray\n",
    "    i = 1\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "    \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "        currentFrame = gray\n",
    "        \n",
    "        foreground = cv2.absdiff(backgroundFrame, currentFrame)\n",
    "\n",
    "        foreground = cv2.threshold(foreground, threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "        foreground = cv2.dilate(foreground, None, iterations=5)\n",
    "            \n",
    "        cv2.imshow(\"Adaptive FD alpha {0} threshold {1}\".format(alpha, threshold), foreground)\n",
    "         \n",
    "        backgroundFrame = cv2.addWeighted(currentFrame, alpha, backgroundFrame, 1.0-alpha,0)\n",
    "        key = cv2.waitKey(100) & 0xFF \n",
    "         \n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Times to complete for alpha {0} threshold {1} is {2}'.format(alpha, threshold, time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times to complete for alpha 0.5 threshold 10 is 2.546170949935913\n"
     ]
    }
   ],
   "source": [
    "# Ideal case\n",
    "adaptiveFD('beach.avi',0.5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times to complete for alpha 1 threshold 0 is 1.3493905067443848\n",
      "Times to complete for alpha 1 threshold 5 is 0.12166953086853027\n",
      "Times to complete for alpha 1 threshold 10 is 0.12665748596191406\n",
      "Times to complete for alpha 1 threshold 15 is 0.5116353034973145\n",
      "Times to complete for alpha 1 threshold 20 is 0.13364434242248535\n",
      "Times to complete for alpha 1 threshold 25 is 0.12505531311035156\n",
      "Times to complete for alpha 1 threshold 30 is 0.10571813583374023\n",
      "Times to complete for alpha 0.75 threshold 0 is 0.10870957374572754\n",
      "Times to complete for alpha 0.75 threshold 5 is 0.11070680618286133\n",
      "Times to complete for alpha 0.75 threshold 10 is 0.9714035987854004\n",
      "Times to complete for alpha 0.75 threshold 15 is 0.5192549228668213\n",
      "Times to complete for alpha 0.75 threshold 20 is 0.09973406791687012\n",
      "Times to complete for alpha 0.75 threshold 25 is 0.0827796459197998\n",
      "Times to complete for alpha 0.75 threshold 30 is 0.10970687866210938\n",
      "Times to complete for alpha 0.5 threshold 0 is 0.11170172691345215\n",
      "Times to complete for alpha 0.5 threshold 5 is 0.10871124267578125\n",
      "Times to complete for alpha 0.5 threshold 10 is 0.09973931312561035\n",
      "Times to complete for alpha 0.5 threshold 15 is 0.11070680618286133\n",
      "Times to complete for alpha 0.5 threshold 20 is 0.529538631439209\n",
      "Times to complete for alpha 0.5 threshold 25 is 0.17453312873840332\n",
      "Times to complete for alpha 0.5 threshold 30 is 0.1575772762298584\n",
      "Times to complete for alpha 0.25 threshold 0 is 0.16854572296142578\n",
      "Times to complete for alpha 0.25 threshold 5 is 0.1545860767364502\n",
      "Times to complete for alpha 0.25 threshold 10 is 0.1625657081604004\n",
      "Times to complete for alpha 0.25 threshold 15 is 0.16855287551879883\n",
      "Times to complete for alpha 0.25 threshold 20 is 0.3381016254425049\n",
      "Times to complete for alpha 0.25 threshold 25 is 0.7706680297851562\n",
      "Times to complete for alpha 0.25 threshold 30 is 0.5116333961486816\n",
      "Times to complete for alpha 0 threshold 0 is 0.173537015914917\n",
      "Times to complete for alpha 0 threshold 5 is 0.16954660415649414\n",
      "Times to complete for alpha 0 threshold 10 is 0.4797179698944092\n",
      "Times to complete for alpha 0 threshold 15 is 0.22040963172912598\n",
      "Times to complete for alpha 0 threshold 20 is 0.3251352310180664\n",
      "Times to complete for alpha 0 threshold 25 is 0.268280029296875\n",
      "Times to complete for alpha 0 threshold 30 is 0.3111684322357178\n"
     ]
    }
   ],
   "source": [
    "alphas = [1, 0.75, 0.5, 0.25, 0]\n",
    "thresholds = [0,5,10,15,20,25,30]\n",
    "sequences = ['beach.avi', 'trees.avi', 'lights.avi', 'jug.avi', 'railway.avi', 'rock.avi']\n",
    "for sequence in sequences:\n",
    "    for alpha in alphas:\n",
    "        for threshold in thresholds:\n",
    "            adaptiveFD(sequence, alpha,threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Persistant frame differencing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is responsive to changes in illumination and camera motion, the ghosts fade away. Objects leave behind the fading trails of pixels. The gradient of this trail indicated the apparent direction of object motion in the image.\n",
    "\n",
    "Thresholds = [0,5,10,15,20,25,30]\n",
    "\n",
    "As the threshold value increases, the motion of the objects and the object itself gets insignificant. Even low threshold values do not show significant motion. Threshold value of 25 seems optimal.\n",
    "\n",
    "Gammas = [0, 0.03, 0.06, 0.09, 0.12, 1]\n",
    "\n",
    "As the value of gamma decreases, the history of the image is more clearly seen. Noticeably, gamma value of 0.09 is ideal. As the value of gamma increases, the fading effect is insignificant with the patches of previous frame opaque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistent Backgrounding\n",
    "def persistentFD(inputfile, threshold, gamma):\n",
    "    cap = video.create_capture(inputfile)\n",
    "    ret, first = cap.read()\n",
    "\n",
    "    # For background subtraction, Save the first image as reference\n",
    "    first_gray = cv2.cvtColor(first, cv2.COLOR_BGR2GRAY)\n",
    "    first_gray = cv2.GaussianBlur(first_gray, (21, 21), 0)\n",
    "    \n",
    "    backgroundFrame = first_gray\n",
    "    \n",
    "    h, w = first_gray.shape[:2]\n",
    "    start = time.time()\n",
    "    mh = np.zeros((h, w),np.float32)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "    \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "        currentFrame = gray\n",
    "        \n",
    "        foreground = cv2.absdiff(backgroundFrame, currentFrame)\n",
    "\n",
    "        foreground = cv2.threshold(foreground, threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "        foreground = cv2.dilate(foreground, None, iterations = 5)\n",
    "        \n",
    "        mh = mh - gamma\n",
    "        mh[mh < 0] = 0\n",
    "        tmp = mh\n",
    "        \n",
    "        foreground = 255 * foreground\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                \n",
    "                if foreground[i, j] > tmp[i, j]:\n",
    "                    mh[i,j] = foreground[i, j]\n",
    "                else:\n",
    "                    mh[i,j] = tmp[i, j] \n",
    "        \n",
    "        cv2.imshow(\"Persistent frame differencing on {0} with threshold = {1} gamma = {2}\".format(inputfile, threshold, gamma) ,mh)\n",
    "        backgroundFrame = currentFrame\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF \n",
    "    \n",
    "        # if the `q` key is pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Time taken for threshold {0}: '.format(threshold) + str(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for threshold 10: 7.293838262557983\n"
     ]
    }
   ],
   "source": [
    "# Ideal case\n",
    "persistentFD('beach.avi', 10, 0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for threshold 0: 80.92021751403809\n",
      "Time taken for threshold 0: 86.73180937767029\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-03958f3d23aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgammas\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mpersistentFD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-40-05c5dc4d99fd>\u001b[0m in \u001b[0;36mpersistentFD\u001b[1;34m(inputfile, threshold, gamma)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mforeground\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m                     \u001b[0mmh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforeground\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gammas = [0, 0.03, 0.06, 0.09, 0.12, 1]\n",
    "thresholds = [0, 5,10,15,20,25,30]\n",
    "sequences = ['beach.avi', 'trees.avi', 'lights.avi', 'jug.avi', 'railway.avi', 'rock.avi']\n",
    "for sequence in sequences:\n",
    "    for threshold in thresholds:    \n",
    "        for gamma in gammas:\n",
    "            persistentFD(sequence,threshold, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
